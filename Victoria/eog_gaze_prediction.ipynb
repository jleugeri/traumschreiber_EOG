{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eog gaze prediction###\n",
    "\n",
    "This program is an extensions of Patrick's eye tracking Data Analysis. \n",
    "\n",
    "The goal is to figure out if a persons eye gaze position on the screen can be predicted by using linear regression and the recorded EOG data. \n",
    "\n",
    "Patrick's part of the program was translated to Pandas Data Frames for further use. The main and final Data Frame is called accepted_data_df, which contains the following information:\n",
    "\n",
    "- Time stamp: Corresponding time\n",
    "- ch0, ch1 and ch2: Eog data\n",
    "- x and y: x and y coordinates corresponding to the point presented on the screen\n",
    "- calibration point: Boolean\n",
    "- stimulus: Boolean\n",
    "- window: corresponding window number\n",
    "- Peak1_media and Peak2_media: The Difference of Gaussians peak (DoG) time stamp median between ch0, ch1 and ch2\n",
    "- ch0Peak1, ch1Peak1 and ch2Peak1: DoG for each channel\n",
    "- ch0Peak2, ch1Peak2 and ch2Peak2: DoG second peak for each channel\n",
    "- rejected: Boolean\n",
    "- x_start and y_start: x and y coordinates at the start of a window\n",
    "- x_end and y_end: x and y coordinates at the end of a window\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import scipy.signal\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (16, 10)\n",
    "filenames = 'data/run{}.csv'\n",
    "datasets = []\n",
    "for i in range(3):\n",
    "    data = pd.read_csv(filenames.format(i), delimiter = \", \", comment = \"#\")\n",
    "    datasets.append(data)\n",
    "\n",
    "datasets_df = pd.concat(datasets)\n",
    "datasets_df = datasets_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filters\n",
    " Data on Channel 1,2 and 3 are not damaged and are going to be used for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Select useful Data\n",
    "valid_datasets_df = datasets_df.loc[:, ('t','ch1','ch2','ch3','x','y','run')]\n",
    "valid_datasets_df.columns = ['time stamp', 'ch0','ch1','ch2','x','y','run']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Median filter\n",
    "filtered_datasets_df = valid_datasets_df.copy()\n",
    "filtered_datasets_df[['ch0','ch1','ch2']] = sp.signal.medfilt(filtered_datasets_df[['ch0','ch1','ch2']], kernel_size=(3, 1)) \n",
    "plt.figure()\n",
    "plt.plot(filtered_datasets_df[['ch0','ch1','ch2']].head(5000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding stimulus times and calibration points\n",
    "\n",
    "A stimulus corresponds to the point on screen changing position. We need to get the indices of stimuli changes, then we can take a look at the EOG data in a window around stimuli to filter out bad ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Adds to dataframe information about calibration points\n",
    "calib_df = pd.DataFrame()\n",
    "calib_df['calib_x'] = filtered_datasets_df['x'].isin([50.0, 2510.0,1280.0])\n",
    "calib_df['calib_y'] = filtered_datasets_df['y'].isin([50.0, 2510.0,1280.0])\n",
    "\n",
    "filtered_datasets_df[\"calibration point\"] = np.nan\n",
    "filtered_datasets_df[\"calibration point\"]= calib_df[['calib_x','calib_y']].applymap(lambda x: True if (x == True) else False)\n",
    "\n",
    "filtered_datasets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Adds to dataframe information about stimulus times\n",
    "stimulus_df = filtered_datasets_df[['x','y']].copy()\n",
    "stimulus_df['stimulus_x'] = stimulus_df['x'].shift() != stimulus_df['x']\n",
    "stimulus_df['stimulus_y'] = stimulus_df['y'].shift() != stimulus_df['y']\n",
    "\n",
    "#Finds stimulus points\n",
    "filtered_datasets_df['stimulus'] = np.nan\n",
    "filtered_datasets_df['stimulus']= stimulus_df[['stimulus_x','stimulus_y']].applymap(lambda x: True if (x == True) else False)\n",
    "filtered_datasets_df['stimulus'].iloc[0] = False\n",
    "\n",
    "#Stimulus index\n",
    "stimulus_idxs = filtered_datasets_df[ filtered_datasets_df['stimulus'] == True].index\n",
    "\n",
    "#Stimulus time stamp\n",
    "stimulus_time_stamps = filtered_datasets_df[ filtered_datasets_df['stimulus'] == True]['time stamp']\n",
    "filtered_datasets_df.loc[filtered_datasets_df['stimulus'] == True].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Difference of Gaussians for transition detection\n",
    "The difference of gaussians filter provides a good way to detect rapid changes in a signal. We try to use it to find the times where the signal switches after stimulus exposure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dog_peaks(data_window,window_nr,rejected):\n",
    "    \n",
    "    size = 21\n",
    "    s1 = 5\n",
    "    s2 = 10\n",
    "    kernel1 = sp.signal.gaussian(size, s1)\n",
    "    kernel1 /= sum(kernel1)\n",
    "    kernel2 = sp.signal.gaussian(size, s2)\n",
    "    kernel2 /= sum(kernel2)\n",
    "    data_window = data_window.reset_index()\n",
    "  \n",
    "    channels =  data_window[['ch0','ch1','ch2']]\n",
    "  \n",
    "    # smooth data\n",
    "    smoothed_eog1 = np.apply_along_axis(lambda channel: sp.signal.convolve(channel, kernel1, mode='valid'), 0, channels)\n",
    "    smoothed_eog2 = np.apply_along_axis(lambda channel: sp.signal.convolve(channel, kernel2, mode='valid'), 0, channels)\n",
    "\n",
    "    smoothed_eog1 = pd.DataFrame(smoothed_eog1)\n",
    "    smoothed_eog1.columns = ['ch0','ch1','ch2']\n",
    "    smoothed_eog2 = pd.DataFrame(smoothed_eog2)\n",
    "    smoothed_eog2.columns = ['ch0','ch1','ch2']\n",
    "    \n",
    "    # smoothing removed border points\n",
    "    data_window = data_window[10:-10]\n",
    "    data_window.reset_index(inplace = True, drop= True)\n",
    "    \n",
    "    # calculate Difference of Gaussians\n",
    "    dogs = smoothed_eog1 - smoothed_eog2\n",
    " \n",
    "    # calculate absolute DoG values\n",
    "    abs_dogs = np.abs(dogs)\n",
    "    data_window[['ch0 abs dogs','ch1 abs dogs','ch2 abs dogs']] = abs_dogs\n",
    "    \n",
    "    # Find peaks\n",
    "    abs_dogs[['ch0 peak','ch1 peak','ch2 peak']] = abs_dogs[['ch0','ch1','ch2']].apply(lambda x:(x > x.shift())&(x.iloc[::-1] > x.iloc[::-1].shift()))\n",
    "    data_window[['ch0 peak','ch1 peak','ch2 peak']] = abs_dogs[['ch0 peak','ch1 peak','ch2 peak']]\n",
    "    data_window.set_index(\"time stamp\", inplace = True)\n",
    "    abs_dogs_peaks = data_window[['ch0 abs dogs','ch1 abs dogs','ch2 abs dogs','ch0 peak','ch1 peak','ch2 peak']]\n",
    "    channels = ['ch0{}{}','ch1{}{}','ch2{}{}']\n",
    "    \n",
    "    first_peaks_time =[]\n",
    "    second_peaks_time = []\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    \n",
    "    for chan in channels:\n",
    "        max_peak = abs_dogs_peaks.loc[abs_dogs_peaks[chan.format(' peak','')] == True]\n",
    "       \n",
    "        #Gets the maximal peaks values for each channel\n",
    "        max_peak_ch = max_peak[chan.format(' abs',' dogs')].nlargest(2)\n",
    "        max_peak_ch = max_peak_ch.reset_index()\n",
    "       \n",
    "        if len(max_peak_ch) > 1:\n",
    "            x = max_peak_ch.values[0][0],max_peak_ch.values[1][0]\n",
    "            y = max_peak_ch.values[0][1],max_peak_ch.values[1][1]\n",
    "            \n",
    "            x_list.append(x)\n",
    "            y_list.append(y)\n",
    "            first_peaks_time.append(max_peak_ch.values[0][0])\n",
    "            second_peaks_time.append(max_peak_ch.values[1][0])\n",
    "            filtered_datasets_df[chan.format('Peak','1')].loc[filtered_datasets_df['time stamp'] == max_peak_ch.values[0][0]] = True\n",
    "            filtered_datasets_df[chan.format('Peak','2')].loc[filtered_datasets_df['time stamp'] == max_peak_ch.values[1][0]] = True\n",
    "            \n",
    "        else:\n",
    "            rejected = True\n",
    "    \n",
    "    #Rejects samples, where the minimal distance to the median is less than 20 miliseconds\n",
    "    sort_fp_times = np.sort(first_peaks_time)\n",
    "    sort_sp_times = np.sort(second_peaks_time)\n",
    "   \n",
    "    diffs_fp = np.absolute(sort_fp_times [:2] - sort_fp_times [1:]) * 1000\n",
    "    diffs_sp = np.absolute(sort_sp_times [:2] - sort_sp_times [1:]) * 1000\n",
    "    diffs_fp.sort()\n",
    "    diffs_sp.sort()\n",
    " \n",
    "    if  len(diffs_fp) > 0 and len(diffs_sp) > 0:\n",
    "        if diffs_fp[0] > 20 or diffs_sp[0] > 20 :\n",
    "            rejected = True\n",
    "    #Reject samples where second Dog peak is found before the first Dog peak\n",
    "    if (sort_sp_times[1]-sort_fp_times[1]) < 0.03:\n",
    "        rejected = True    \n",
    "        \n",
    "    # If sample is not rejected, add peaks information to general dataframe and plot the median for first and second dog peaks\n",
    "    \n",
    "    if rejected == False:  \n",
    "        plt.figure()\n",
    "        for i, chan in enumerate(channels):\n",
    "            #Enters information about first and second Dog peaks time media\n",
    "            filtered_datasets_df['Peak1_media'].loc[filtered_datasets_df['time stamp'] == sort_fp_times[1]] = True\n",
    "            filtered_datasets_df['Peak2_media'].loc[filtered_datasets_df['time stamp'] == sort_sp_times[1]] = True\n",
    "            \n",
    "            plt.plot(data_window[['ch0 abs dogs','ch1 abs dogs','ch2 abs dogs']])\n",
    "            plt.scatter(x_list[i],y_list[i],color= 'r')\n",
    "            plt.axvline(sort_fp_times[1], color= 'blue')\n",
    "            plt.axvline(sort_sp_times[1], color= 'green')\n",
    "            plt.title('Difference of Gaussians First and Second Peak, Window {}'.format(window_nr))\n",
    "            plt.xlabel('time (seconds)')\n",
    "            plt.ylabel('EOG data')\n",
    "            plt.legend()\n",
    "    \n",
    "    plt.show()      \n",
    "    return rejected, window_nr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stimulus analysis in Data Windows\n",
    "\n",
    "At this point the data is organized in time windows, which start with a stimulus and end just before the next stimulus is presented. Difference of Gaussians is used to identify main signal switches. This step allows to reject samples that are too noisy or corrupted. Difference of Gaussians first and Second peaks are going to be used as features for linear regression.\n",
    "This cell will run for a while (about 10 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_datasets_df['window'] = np.nan\n",
    "filtered_datasets_df[['Peak1_media','Peak2_media','ch0Peak1','ch1Peak1','ch2Peak1','ch0Peak2','ch1Peak2','ch2Peak2','rejected']]= pd.DataFrame([[False, False,False, False, False,False, False, False, False]], index=filtered_datasets_df.index)\n",
    "filtered_datasets_df[['x_start','y_start','x_end','y_end']]= pd.DataFrame([[False, False,False, False]], index=filtered_datasets_df.index)\n",
    "count= 0\n",
    "window_nr = 0\n",
    "stim_idx_prev = 0\n",
    "for i,stim_idx in enumerate(stimulus_idxs[0:-1]):\n",
    "    rejected = False\n",
    "    data_window = filtered_datasets_df.iloc[stim_idx:stimulus_idxs[i+1]].copy()\n",
    "  \n",
    "    if  stim_idx in data_window.index:\n",
    "    \n",
    "        filtered_datasets_df['window'].iloc[stim_idx:stimulus_idxs[i+1]] = window_nr\n",
    "        stim_time_stamp = data_window['time stamp'].loc[stim_idx]\n",
    "        data_window = data_window.set_index(['time stamp'])\n",
    "        \n",
    "        #Enter information about start and end coordinates for the window\n",
    "        filtered_datasets_df['x_start'].iloc[stim_idx_prev] = True\n",
    "        filtered_datasets_df['y_start'].iloc[stim_idx_prev] = True\n",
    "        filtered_datasets_df['x_end'].iloc[stim_idx] = True\n",
    "        filtered_datasets_df['y_end'].iloc[stim_idx] = True\n",
    "        stim_idx_prev = stim_idx\n",
    "\n",
    "    else:\n",
    "        rejected = True\n",
    "        pass  \n",
    "    \n",
    "    if len(data_window) > 270:\n",
    "        rejected = True\n",
    "        \n",
    "    #Calculate DOG first and second peaks, enters iformation in Dataframe\n",
    "    if rejected == False:\n",
    "        rejected, window_nr = get_dog_peaks(data_window,window_nr,rejected)\n",
    "\n",
    "    \n",
    "    data_window = filtered_datasets_df.loc[filtered_datasets_df['window'] == window_nr]\n",
    "    \n",
    "    peak1_media_stamp = data_window['time stamp'].loc[data_window['Peak1_media'] == True].values\n",
    "    peak2_media_stamp = data_window['time stamp'].loc[data_window['Peak2_media'] == True].values\n",
    "    \n",
    "    if len(peak2_media_stamp) > 1 or len(peak1_media_stamp) >1:\n",
    "        rejected = True   \n",
    "        \n",
    "    if rejected == True:\n",
    "        filtered_datasets_df['rejected'].loc[filtered_datasets_df['window'] == window_nr] = True\n",
    "        window_nr += 1\n",
    "\n",
    "    if rejected == False:\n",
    "        plt.figure()\n",
    "        plt.plot(data_window['time stamp'],data_window[['ch0','ch1','ch2']])\n",
    "        plt.title('First and Second DoG Peaks to detect main signal switches in EOG Data')\n",
    "        plt.xlabel('time (seconds)')\n",
    "        plt.ylabel('EOG Data')\n",
    "        plt.axvline(stim_time_stamp, color='r')\n",
    "        plt.axvline(peak1_media_stamp, color='b')\n",
    "        plt.axvline(peak2_media_stamp, color='g')\n",
    "        plt.legend()\n",
    "        window_nr += 1\n",
    "        plt.show()\n",
    "        \n",
    "  \n",
    "   \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect features for Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creates a new data frame will all data windows that were not rejected\n",
    "accepted_datasets_df = filtered_datasets_df[filtered_datasets_df['rejected'] == False].copy()\n",
    "#all x-end points \n",
    "x_start = accepted_datasets_df['x'].loc[accepted_datasets_df['x_start'] == True].reset_index(drop = True)\n",
    "#all y-end points\n",
    "y_start = accepted_datasets_df['y'].loc[accepted_datasets_df['y_start'] == True].reset_index(drop = True)\n",
    "#all x-end points \n",
    "x_end = accepted_datasets_df['x'].loc[accepted_datasets_df['x_end'] == True].reset_index(drop = True)\n",
    "#all y-end points\n",
    "y_end = accepted_datasets_df['y'].loc[accepted_datasets_df['y_end'] == True].reset_index(drop = True)\n",
    "#value for each channel at start point or stimulus point\n",
    "stim_eog0 = accepted_datasets_df['ch0'].loc[accepted_datasets_df['stimulus'] == True].reset_index(drop = True)\n",
    "stim_eog1 = accepted_datasets_df['ch1'].loc[accepted_datasets_df['stimulus'] == True].reset_index(drop = True)\n",
    "stim_eog2 = accepted_datasets_df['ch2'].loc[accepted_datasets_df['stimulus'] == True].reset_index(drop = True)\n",
    "#value for each channel at dog  2\n",
    "dog_2_Ch0 = accepted_datasets_df['ch0'].loc[accepted_datasets_df['ch0Peak2'] == True].reset_index(drop = True)\n",
    "dog_2_Ch1 = accepted_datasets_df['ch1'].loc[accepted_datasets_df['ch1Peak2'] == True].reset_index(drop = True)\n",
    "dog_2_Ch2 = accepted_datasets_df['ch2'].loc[accepted_datasets_df['ch2Peak2'] == True].reset_index(drop = True)\n",
    "#value for each channel at dog  1\n",
    "dog_1_Ch0 = accepted_datasets_df['ch0'].loc[accepted_datasets_df['ch0Peak1'] == True].reset_index(drop = True)\n",
    "dog_1_Ch1 = accepted_datasets_df['ch1'].loc[accepted_datasets_df['ch1Peak1'] == True].reset_index(drop = True)\n",
    "dog_1_Ch2 = accepted_datasets_df['ch2'].loc[accepted_datasets_df['ch2Peak1'] == True].reset_index(drop = True)\n",
    "#Values for first and secong Dog peaks at peak median\n",
    "dog_1_Ch0_media = accepted_datasets_df['ch0'].loc[accepted_datasets_df['Peak1_media'] == True].reset_index(drop = True)\n",
    "dog_1_Ch1_media = accepted_datasets_df['ch1'].loc[accepted_datasets_df['Peak1_media'] == True].reset_index(drop = True)\n",
    "dog_1_Ch2_media = accepted_datasets_df['ch2'].loc[accepted_datasets_df['Peak1_media'] == True].reset_index(drop = True)\n",
    "dog_2_Ch0_media = accepted_datasets_df['ch0'].loc[accepted_datasets_df['Peak2_media'] == True].reset_index(drop = True)\n",
    "dog_2_Ch1_media = accepted_datasets_df['ch1'].loc[accepted_datasets_df['Peak2_media'] == True].reset_index(drop = True)\n",
    "dog_2_Ch2_media = accepted_datasets_df['ch2'].loc[accepted_datasets_df['Peak2_media'] == True].reset_index(drop = True)\n",
    "#Different combinations for doing linear regresion\n",
    "linear_regression_df = pd.DataFrame(\n",
    "    {'dog_1_Ch0': dog_1_Ch0_media,\n",
    "     'dog_1_Ch1': dog_1_Ch1_media,\n",
    "     'dog_1_Ch2': dog_1_Ch2_media,\n",
    "     'dog_2_Ch0': dog_2_Ch0_media,\n",
    "     'dog_2_Ch1': dog_2_Ch1_media,\n",
    "     'dog_2_Ch2': dog_2_Ch2_media,\n",
    "     'stim_eog0': stim_eog0,\n",
    "     'stim_eog1': stim_eog1,\n",
    "     'stim_eog2': stim_eog2,\n",
    "     'x_start': x_start,\n",
    "     'y_start': y_start,\n",
    "     'x_end': x_end,\n",
    "     'y_end': y_end})\n",
    "\n",
    "linear_regression_df.drop(linear_regression_df.tail(1).index,inplace=True)\n",
    "linear_regression_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "The values of channel 0,1 and 2 at DoG peaks 1 and 2 are used as features for the linear regression.\n",
    "The regression targets are the x and y coordinates at stimulus time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Regression with second Dog peaks, start coordinates and stimulus\n",
    "%matplotlib notebook\n",
    "#Split data frame in data and targets\n",
    "regression_data = linear_regression_df.loc[:,['dog_2_Ch0','dog_2_Ch1','dog_2_Ch2','dog_1_Ch0','dog_1_Ch1','dog_1_Ch2']]\n",
    "\n",
    "regression_targets = linear_regression_df.loc[:, ['x_end','y_end']]\n",
    "                        \n",
    "# Split the data into training/testing sets\n",
    "eog_ch_train = regression_data[:210]\n",
    "eog_ch_test = regression_data[210:]\n",
    "\n",
    "# Split the targets into training/testing sets\n",
    "eog_coor_train = regression_targets[:210]\n",
    "eog_coor_test = regression_targets[210:]\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(eog_ch_train, eog_coor_train)\n",
    "# Make predictions using the testing set\n",
    "eog_coor_pred = regr.predict(eog_ch_test)\n",
    "\n",
    "# The coefficients\n",
    "print('Regression with second Dog peaks, start coordinates and stimulus')\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(eog_coor_test, eog_coor_pred))\n",
    "print(\"Distance in pixels: %.2f \" % np.sqrt(mean_squared_error(eog_coor_test, eog_coor_pred)))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(eog_coor_test, eog_coor_pred))\n",
    "\n",
    "# Plot outputs\n",
    "n = eog_coor_test.shape[0]\n",
    "fig3 = plt.figure(figsize=(14, 8))\n",
    "    # create the function that will do the plotting, where curr is the current frame\n",
    "def update(curr):\n",
    "     \n",
    "    # check if animation is at the last frame, and if so, stop the animation.\n",
    "    if curr == n: \n",
    "        a.event_source.stop()\n",
    "    \n",
    "    plt.scatter(eog_coor_pred[0:curr,0] ,eog_coor_pred[0:curr,1], color = \"red\")\n",
    "    plt.scatter(eog_coor_test.iloc[0:curr, [0]] ,eog_coor_test.iloc[0:curr, [1]], color = 'blue')\n",
    "    plt.xlim(0, 2560)\n",
    "    plt.ylim(1440, 0)\n",
    "    plt.show()\n",
    "   \n",
    "    \n",
    "    \n",
    "a = animation.FuncAnimation(fig3, update, interval=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Gaze predictions in quadrants\n",
    "\n",
    "The screen is divided in 9 quadrants in order to know how often the prediction falls into the same section as the true stimulus coordinates.\n",
    "A possible improvement for this section could be to convert the area into Polar coordinates and predict quadrants by the direccion of gaze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Adds quadrant label to each prediction and test point\n",
    "def quadrand_labels(df):\n",
    "    df['quadrant label'] = 0   \n",
    "    for i, row in enumerate(df.iterrows()):\n",
    "            x = df.loc[i,'x']\n",
    "            y = df.loc[i,'y']\n",
    "\n",
    "            if x >=0 and x <854:\n",
    "                if y >=960 and y <= 1440:\n",
    "                    df.loc[i,'quadrant label'] = 1\n",
    "                elif y >=480 and y < 960:\n",
    "                    df.loc[i,'quadrant label'] = 4\n",
    "                elif y >=0 and y < 480:\n",
    "                    df.loc[i,'quadrant label'] = 7\n",
    "            elif x >=854 and x <1708:\n",
    "                if y >=960 and y <= 1440:\n",
    "                    df.loc[i,'quadrant label'] = 2\n",
    "                elif y >=480 and y < 960:\n",
    "                    df.loc[i,'quadrant label'] = 5\n",
    "                elif y >=0 and y < 480:\n",
    "                    df.loc[i,'quadrant label'] = 8\n",
    "            elif x >=1708 and x <=2562:\n",
    "                if y >=960 and y <= 1440:\n",
    "                    df.loc[i,'quadrant label'] = 3\n",
    "                elif y >=480 and y < 960:\n",
    "                    df.loc[i,'quadrant label'] = 6\n",
    "                elif y >=0 and y < 480:\n",
    "                    df.loc[i,'quadrant label'] = 9\n",
    "\n",
    "    return df\n",
    "\n",
    "eog_coor_pred_df = pd.DataFrame(eog_coor_pred,columns=['x','y'] )\n",
    "\n",
    "eog_coor_test.columns = ['x','y'] \n",
    "eog_coor_test.reset_index(inplace = True, drop = True)\n",
    "labeled_predict = quadrand_labels(eog_coor_pred_df)\n",
    "labeled_test = quadrand_labels(eog_coor_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creates grid for classifying data in quadrants\n",
    "calibration_points = [\n",
    "    (50, 50),\n",
    "    (2510, 50),\n",
    "    (50, 1390),\n",
    "    (2510, 1390),\n",
    "    (1280, 720)\n",
    "]\n",
    "n = len(eog_coor_test)\n",
    "fig5 = plt.figure(figsize=(14, 8))\n",
    "def update(curr):\n",
    "   \n",
    "    # Animation\n",
    "    if curr == n: \n",
    "        a.event_source.stop()\n",
    " \n",
    "    plt.xlim(0, 2560)\n",
    "    plt.ylim(1440, 0)\n",
    "    plt.gca().set_aspect('equal', 'box')\n",
    "    plt.legend()\n",
    "    plt.axvline(854, color='black')\n",
    "    plt.axvline(1708, color='black')\n",
    "    plt.axhline(480, color='black')\n",
    "    plt.axhline(960, color='black')\n",
    "    plt.scatter(eog_coor_pred[curr][0] ,eog_coor_pred[curr][1], color = \"red\")\n",
    "    plt.scatter(eog_coor_test['x'].iloc[curr],eog_coor_test['y'].iloc[curr] , color = 'blue')\n",
    "    plt.xlim(0, 2560)\n",
    "    plt.ylim(1440, 0)\n",
    "    if labeled_test['quadrant label'].iloc[curr] == labeled_predict['quadrant label'].iloc[curr]:\n",
    "        plt.title('Stimulus nr {} : Match'.format(curr))\n",
    "    else:\n",
    "        plt.title('Stimulus nr {} : Mismatch'.format(curr))\n",
    "    plt.show()\n",
    "        \n",
    "a = animation.FuncAnimation(fig5, update, interval=1500)\n",
    "\n",
    "# Percentage of matches\n",
    "total_match = sum(labeled_test['quadrant label'] == labeled_predict['quadrant label'])\n",
    "print('Total match is {} from {}, {}% match'.format(total_match,len(eog_coor_pred_df),((total_match*100)/len(eog_coor_pred_df)).astype(int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaze draw prediction\n",
    "This part tests if the figures formed by connecting the stimulus coordinates can be replicated by the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Plot of experiment stimulus points\n",
    "%matplotlib notebook\n",
    "stimulus_df = accepted_datasets_df[accepted_datasets_df['stimulus'] == 1]\n",
    "stim_x_no_calib = stimulus_df[stimulus_df['calibration point'] == 0]\n",
    "#stimulus_time = stimulus_df['time stamp']\n",
    "stimulus_x = stimulus_df['x']\n",
    "stimulus_y = stimulus_df['y']\n",
    "stimulus_df.reset_index(inplace= True)\n",
    "\n",
    "fig = plt.figure(figsize= (12,6))\n",
    "plt.xlim(0, 2560)\n",
    "plt.ylim(1440, 0)\n",
    "\n",
    "n = 11\n",
    "def update(curr):\n",
    "    \n",
    "    # check if animation is at the last frame, and if so, stop the animation.\n",
    "    if curr == 11: \n",
    "        a.event_source.stop()   \n",
    "        \n",
    "    if stimulus_df.loc[curr,'calibration point'] == 1.0:\n",
    "        plt.clf()\n",
    "        plt.xlim(0, 2560)\n",
    "        plt.ylim(1440, 0)\n",
    "        plt.title(curr)\n",
    "        plt.axvline(854, color='black')\n",
    "        plt.axvline(1708, color='black')\n",
    "        plt.axhline(480, color='black')\n",
    "        plt.axhline(960, color='black')\n",
    "        plt.gca().set_aspect('equal', 'box')\n",
    "        #plt.scatter(eog_coor_pred[0:curr,0] ,eog_coor_pred[0:curr,1], color = \"blue\")\n",
    "        plt.scatter(stimulus_df.loc[curr , 'x'] ,stimulus_df.loc[curr , 'y'])#, markersize=20)\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        plt.clf()\n",
    "        plt.xlim(0, 2560)\n",
    "        plt.ylim(1440, 0)\n",
    "        plt.title(curr)\n",
    "        plt.axvline(854, color='black')\n",
    "        plt.axvline(1708, color='black')\n",
    "        plt.axhline(480, color='black')\n",
    "        plt.axhline(960, color='black')\n",
    "        plt.gca().set_aspect('equal', 'box') \n",
    "        plt.plot(eog_coor_pred[0:curr,0] ,eog_coor_pred[0:curr,1], color = \"red\")\n",
    "        plt.plot(eog_coor_test.iloc[0:curr,[0]] ,eog_coor_test.iloc[0:curr, [1]], color = 'blue')\n",
    "        plt.show()\n",
    "       \n",
    "    \n",
    "gaze_draw = animation.FuncAnimation(fig, update, interval=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
